{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Nova.lite and Nova.pro on MeetingBank Dataset\n",
    "\n",
    "This notebook demonstrates how to evaluate Amazon Bedrock models (Nova.lite and Nova.pro) on the MeetingBank dataset for meeting summarization tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "\n",
    "# Import utility functions\n",
    "from utils.dataset_utils import load_meetingbank_dataset, get_test_samples, prepare_for_bedrock_evaluation\n",
    "from utils.bedrock_utils import (\n",
    "    create_s3_bucket_if_not_exists,\n",
    "    apply_cors_if_not_exists,\n",
    "    upload_to_s3,\n",
    "    create_evaluation_job,\n",
    "    wait_for_job_completion,\n",
    "    download_evaluation_results\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configure AWS Credentials\n",
    "\n",
    "Make sure you have AWS credentials configured with appropriate permissions for Amazon Bedrock and S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS Identity verified: arn:aws:sts::864016358360:assumed-role/Admin/gili-Isengard\n"
     ]
    }
   ],
   "source": [
    "# Set AWS region\n",
    "region = \"us-east-1\"  # Change to your preferred region where Bedrock is available\n",
    "BEDROCK_ROLE_ARN = \"arn:aws:iam::864016358360:role/service-role/Amazon-Bedrock-IAM-Role-20250531T202875\"\n",
    "bucket_name = 'eval-datasets-us-east-1'\n",
    "NUM_SAMPLES_PER_EVAL = 50\n",
    "\n",
    "# Set IAM role ARN with permissions for Bedrock evaluation\n",
    "# This role needs permissions to access S3 and invoke Bedrock models\n",
    "#os.environ[\"BEDROCK_ROLE_ARN\"] = \"arn:aws:iam::YOUR_ACCOUNT_ID:role/YOUR_BEDROCK_ROLE\"  # Replace with your role ARN\n",
    "os.environ[\"BEDROCK_ROLE_ARN\"] = BEDROCK_ROLE_ARN\n",
    "\n",
    "# Verify AWS credentials\n",
    "try:\n",
    "    sts = boto3.client('sts')\n",
    "    identity = sts.get_caller_identity()\n",
    "    print(f\"AWS Identity verified: {identity['Arn']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error verifying AWS credentials: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load MeetingBank Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset structure: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['summary', 'uid', 'id', 'transcript'],\n",
      "        num_rows: 5169\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['summary', 'uid', 'id', 'transcript'],\n",
      "        num_rows: 861\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['summary', 'uid', 'id', 'transcript'],\n",
      "        num_rows: 862\n",
      "    })\n",
      "})\n",
      "Available splits: dict_keys(['train', 'validation', 'test'])\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset = load_meetingbank_dataset()\n",
    "print(f\"Dataset structure: {dataset}\")\n",
    "print(f\"Available splits: {dataset.keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test samples: 20\n",
      "\n",
      "Sample 1:\n",
      "Transcript length: 7153 characters\n",
      "Summary length: 278 characters\n",
      "Summary: A RESOLUTION encouraging as a best practice the use of an individualized tenant assessment using the Fair Housing Act’s discriminatory effects standard to avoid Fair Housing Act violations when crimin...\n",
      "\n",
      "Sample 2:\n",
      "Transcript length: 2822 characters\n",
      "Summary length: 643 characters\n",
      "Summary: On the message and order, referred on December 1, 2021, Docket #1239, authorizing the creation of a Sheltered Market Program in conformity with the requirements of G.L.C Chapter 30 B Section 18. This ...\n",
      "\n",
      "Sample 3:\n",
      "Transcript length: 1381 characters\n",
      "Summary length: 350 characters\n",
      "Summary: Adopt resolution consenting to inclusion of certain properties within the jurisdiction in the California HERO Program to finance distributed generation renewable energy sources, energy and water effic...\n",
      "\n",
      "Sample 4:\n",
      "Transcript length: 37394 characters\n",
      "Summary length: 644 characters\n",
      "Summary: AN ORDINANCE relating to transportation concurrency; adopting a new concurrency test results map; adopting a new map indicating the boundaries of the concurrency travel sheds; and amending Ordinance 1...\n",
      "\n",
      "Sample 5:\n",
      "Transcript length: 5036 characters\n",
      "Summary length: 251 characters\n",
      "Summary: AN ORDINANCE relating to the Department of Parks and Recreation; authorizing the acquisition of real property commonly known as 5104 SW Orleans Street; and authorizing acceptance and recording of the ...\n",
      "\n",
      "Sample 6:\n",
      "Transcript length: 3370 characters\n",
      "Summary length: 399 characters\n",
      "Summary: Recommendation to receive supporting documentation into the record, conclude the public hearing, find that the area to be vacated is not needed for present or prospective public use; and, adopt resolu...\n",
      "\n",
      "Sample 7:\n",
      "Transcript length: 4339 characters\n",
      "Summary length: 128 characters\n",
      "Summary: Mayor’s Nominations for Appointment to the Commission on Persons with Disabilities and Housing Authority Board of Commissioners....\n",
      "\n",
      "Sample 8:\n",
      "Transcript length: 5936 characters\n",
      "Summary length: 354 characters\n",
      "Summary: Recommendation to authorize City Manager, or designee, to execute all necessary documents to amend the U.S. Economic Development Administration (EDA) Revolving Loan Fund, to create the Long Beach Emer...\n",
      "\n",
      "Sample 9:\n",
      "Transcript length: 2673 characters\n",
      "Summary length: 921 characters\n",
      "Summary: Recommendation to request City Council to receive and file the certification of the petition regarding the Regulation of Medical Marijuana Businesses; and approve one of the following three alternativ...\n",
      "\n",
      "Sample 10:\n",
      "Transcript length: 1613 characters\n",
      "Summary length: 254 characters\n",
      "Summary: Recommendation to adopt resolution approving an exception to the 180-day waiting period for Public Agencies pursuant to Government Code 7522.56 and 21224 to hire Charles Tripp for a limited duration t...\n",
      "\n",
      "Sample 11:\n",
      "Transcript length: 39066 characters\n",
      "Summary length: 925 characters\n",
      "Summary: Recommendation to authorize City Manager, or designee, to execute all documents necessary for the Second Amendment to Project Labor Agreement (PLA) No. 33859 between the City of Long Beach and the Los...\n",
      "\n",
      "Sample 12:\n",
      "Transcript length: 6616 characters\n",
      "Summary length: 156 characters\n",
      "Summary: Adoption of Resolutions Appointing Kathryn Beehler and Reappointing Lisa Hall and Jennifer Roloff as Members of the Commission on Persons with Disabilities....\n",
      "\n",
      "Sample 13:\n",
      "Transcript length: 1409 characters\n",
      "Summary length: 123 characters\n",
      "Summary: Recommendation to adopt resolution approving the Proposed Fiscal Year 2016 Harbor Department Salary Resolution No. HD-2822....\n",
      "\n",
      "Sample 14:\n",
      "Transcript length: 944 characters\n",
      "Summary length: 743 characters\n",
      "Summary: A resolution approving a proposed Standard Concession Agreement between the City and County of Denver and Paradies Lagardere @ DEN 2017, LLC concerning concessions on Concourse A at Denver Internation...\n",
      "\n",
      "Sample 15:\n",
      "Transcript length: 5017 characters\n",
      "Summary length: 245 characters\n",
      "Summary: Recommendation to declare ordinance amending the Land Use District Map of the City of Long Beach as said map has been established and amended by amending portions of Parts 10, 16, 29 and 30 of said ma...\n",
      "\n",
      "Sample 16:\n",
      "Transcript length: 23685 characters\n",
      "Summary length: 282 characters\n",
      "Summary: A bill for an ordinance naming the park at 2140 West Asbury Avenue as “La Lomita Park”. Approves the naming of the park at Asbury and Tejon as La Lomita Park located at 2140 West Asbury Avenue in Coun...\n",
      "\n",
      "Sample 17:\n",
      "Transcript length: 9781 characters\n",
      "Summary length: 277 characters\n",
      "Summary: A bill for an ordinance designating 1168 South Gilpin Street as a structure for preservation. Approves an individual landmark designation for property located at 1168 South Gilpin Street in Council Di...\n",
      "\n",
      "Sample 18:\n",
      "Transcript length: 2271 characters\n",
      "Summary length: 355 characters\n",
      "Summary: AN ORDINANCE relating to grant funds from non-City sources; authorizing the Seattle Police Department to accept specified grants and execute related agreements for and on behalf of the City; amending ...\n",
      "\n",
      "Sample 19:\n",
      "Transcript length: 4775 characters\n",
      "Summary length: 184 characters\n",
      "Summary: Recommendation to Approve the Amended and Restated Maintenance and Cost Sharing Agreement between the City of Alameda and Alameda West Lagoon Homeowners Association. (Public Works 351)...\n",
      "\n",
      "Sample 20:\n",
      "Transcript length: 4952 characters\n",
      "Summary length: 538 characters\n",
      "Summary: Recommendation to increase appropriations in the General Fund Group in the City Manager Department by $5,000, offset by the Eighth Council District One-time District Priority Funds transferred from th...\n"
     ]
    }
   ],
   "source": [
    "# Get the first {NUM_SAMPLES_PER_EVAL} samples from the test set\n",
    "test_samples = get_test_samples(dataset, num_samples=NUM_SAMPLES_PER_EVAL)\n",
    "print(f\"Number of test samples: {len(test_samples)}\")\n",
    "\n",
    "# Display sample information\n",
    "for i, sample in enumerate(test_samples):\n",
    "    print(f\"\\nSample {i+1}:\")\n",
    "    print(f\"Transcript length: {len(sample['transcript'])} characters\")\n",
    "    print(f\"Summary length: {len(sample['summary'])} characters\")\n",
    "    print(f\"Summary: {sample['summary'][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare Dataset for Bedrock Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation dataset created at: ./data/bedrock_evaluation_dataset.jsonl\n",
      "\n",
      "Record 1:\n",
      "Prompt length: 7198 characters\n",
      "Reference response length: 278 characters\n",
      "Category: meeting_summarization\n",
      "\n",
      "Record 2:\n",
      "Prompt length: 2867 characters\n",
      "Reference response length: 643 characters\n",
      "Category: meeting_summarization\n",
      "\n",
      "Record 3:\n",
      "Prompt length: 1426 characters\n",
      "Reference response length: 350 characters\n",
      "Category: meeting_summarization\n",
      "\n",
      "Record 4:\n",
      "Prompt length: 37439 characters\n",
      "Reference response length: 644 characters\n",
      "Category: meeting_summarization\n",
      "\n",
      "Record 5:\n",
      "Prompt length: 5081 characters\n",
      "Reference response length: 251 characters\n",
      "Category: meeting_summarization\n",
      "\n",
      "Record 6:\n",
      "Prompt length: 3415 characters\n",
      "Reference response length: 399 characters\n",
      "Category: meeting_summarization\n",
      "\n",
      "Record 7:\n",
      "Prompt length: 4384 characters\n",
      "Reference response length: 128 characters\n",
      "Category: meeting_summarization\n",
      "\n",
      "Record 8:\n",
      "Prompt length: 5981 characters\n",
      "Reference response length: 354 characters\n",
      "Category: meeting_summarization\n",
      "\n",
      "Record 9:\n",
      "Prompt length: 2718 characters\n",
      "Reference response length: 921 characters\n",
      "Category: meeting_summarization\n",
      "\n",
      "Record 10:\n",
      "Prompt length: 1658 characters\n",
      "Reference response length: 254 characters\n",
      "Category: meeting_summarization\n",
      "\n",
      "Record 11:\n",
      "Prompt length: 39111 characters\n",
      "Reference response length: 925 characters\n",
      "Category: meeting_summarization\n",
      "\n",
      "Record 12:\n",
      "Prompt length: 6661 characters\n",
      "Reference response length: 156 characters\n",
      "Category: meeting_summarization\n",
      "\n",
      "Record 13:\n",
      "Prompt length: 1454 characters\n",
      "Reference response length: 123 characters\n",
      "Category: meeting_summarization\n",
      "\n",
      "Record 14:\n",
      "Prompt length: 989 characters\n",
      "Reference response length: 743 characters\n",
      "Category: meeting_summarization\n",
      "\n",
      "Record 15:\n",
      "Prompt length: 5062 characters\n",
      "Reference response length: 245 characters\n",
      "Category: meeting_summarization\n",
      "\n",
      "Record 16:\n",
      "Prompt length: 23730 characters\n",
      "Reference response length: 282 characters\n",
      "Category: meeting_summarization\n",
      "\n",
      "Record 17:\n",
      "Prompt length: 9826 characters\n",
      "Reference response length: 277 characters\n",
      "Category: meeting_summarization\n",
      "\n",
      "Record 18:\n",
      "Prompt length: 2316 characters\n",
      "Reference response length: 355 characters\n",
      "Category: meeting_summarization\n",
      "\n",
      "Record 19:\n",
      "Prompt length: 4820 characters\n",
      "Reference response length: 184 characters\n",
      "Category: meeting_summarization\n",
      "\n",
      "Record 20:\n",
      "Prompt length: 4997 characters\n",
      "Reference response length: 538 characters\n",
      "Category: meeting_summarization\n"
     ]
    }
   ],
   "source": [
    "# Prepare the dataset for Bedrock evaluation\n",
    "evaluation_dataset_path = prepare_for_bedrock_evaluation(test_samples)\n",
    "print(f\"Evaluation dataset created at: {evaluation_dataset_path}\")\n",
    "\n",
    "# Display the content of the evaluation dataset\n",
    "with open(evaluation_dataset_path, 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        record = json.loads(line)\n",
    "        print(f\"\\nRecord {i+1}:\")\n",
    "        print(f\"Prompt length: {len(record['prompt'])} characters\")\n",
    "        print(f\"Reference response length: {len(record['referenceResponse'])} characters\")\n",
    "        print(f\"Category: {record['category']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Upload Dataset to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket eval-datasets-us-east-1 already exists\n",
      "CORS configuration already exists for bucket eval-datasets-us-east-1\n",
      "Dataset uploaded to: s3://eval-datasets-us-east-1/evaluation/meetingbank_dataset.jsonl\n",
      "Results will be stored at: s3://eval-datasets-us-east-1/evaluation/results/\n"
     ]
    }
   ],
   "source": [
    "create_s3_bucket_if_not_exists(bucket_name, region)\n",
    "apply_cors_if_not_exists(bucket_name, region)\n",
    "\n",
    "# Upload the evaluation dataset to S3\n",
    "dataset_s3_key = \"evaluation/meetingbank_dataset.jsonl\"\n",
    "dataset_s3_uri = upload_to_s3(evaluation_dataset_path, bucket_name, dataset_s3_key, region)\n",
    "print(f\"Dataset uploaded to: {dataset_s3_uri}\")\n",
    "\n",
    "# Define the output location in S3\n",
    "output_s3_uri = f\"s3://{bucket_name}/evaluation/results/\"\n",
    "print(f\"Results will be stored at: {output_s3_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create and Run Bedrock Evaluation Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: {'name': 'nova-micro', 'model_id': 'us.amazon.nova-micro-v1:0'}\n",
      "Evaluation job created with ARN: arn:aws:bedrock:us-east-1:864016358360:evaluation-job/cgp7gjwllrkf\n"
     ]
    }
   ],
   "source": [
    "# Define the models to evaluate\n",
    "models = [\n",
    "    {\n",
    "        \"name\" : \"nova-micro\",\n",
    "        \"model_id\" : \"us.amazon.nova-micro-v1:0\",\n",
    "    },\n",
    "    {\n",
    "        \"name\" : \"nova-lite\",\n",
    "        \"model_id\" : \"us.amazon.nova-lite-v1:0\",\n",
    "    },\n",
    "    {\n",
    "        \"name\" : \"nova-pro\",\n",
    "        \"model_id\" : \"us.amazon.nova-pro-v1:0\",\n",
    "    },\n",
    "    {\n",
    "        \"name\" : \"nova-premier\",\n",
    "        \"model_id\" : \"us.amazon.nova-premier-v1:0\",\n",
    "    },\n",
    "    {\n",
    "        \"name\" : \"Haiku-3\",\n",
    "        \"model_id\" : \"us.anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    },\n",
    "    {\n",
    "        \"name\" : \"Sonnet-3.5-v2\",\n",
    "        \"model_id\" : \"us.anthropic.claude-3-5-sonnet-20241022-v2:0\",\n",
    "    },\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    print(f\"Model: {model}\")\n",
    "    model_name = model[\"name\"]\n",
    "    model_id = model[\"model_id\"]\n",
    "    # Create a unique job name\n",
    "    job_name = f\"meetingbank-{model_name}-{datetime.now().strftime('%Y%m%d%H%M%S')}\"\n",
    "    model[job_name] = job_name\n",
    "\n",
    "    # Create the evaluation job\n",
    "    try:\n",
    "        job_arn = create_evaluation_job(\n",
    "            job_name=job_name,\n",
    "            dataset_s3_uri=dataset_s3_uri,\n",
    "            output_s3_uri=output_s3_uri,\n",
    "            model_id=model_id,\n",
    "            region=region\n",
    "        )\n",
    "        print(f\"Evaluation job created with ARN: {job_arn}\")\n",
    "        model['job_arn'] = job_arn\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating evaluation job: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name = nova-micro. Job ARN: arn:aws:bedrock:us-east-1:864016358360:evaluation-job/cgp7gjwllrkf\n",
      "Waiting for evaluation job to complete...\n",
      "Job status: InProgress. Waiting 60 seconds...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Wait for the job to complete\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mWaiting for evaluation job to complete...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m job_details = \u001b[43mwait_for_job_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_arn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mJob completed with status: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob_details[\u001b[33m'\u001b[39m\u001b[33mstatus\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/evaluation-gen-ai/mode_eval_meetingbank/utils/bedrock_utils.py:172\u001b[39m, in \u001b[36mwait_for_job_completion\u001b[39m\u001b[34m(job_arn, region, poll_interval)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    job_arn=model['job_arn']\n",
    "    print(f\"name = {model[\"name\"]}. Job ARN: {job_arn}\")\n",
    "    # Wait for the job to complete\n",
    "    print(\"Waiting for evaluation job to complete...\")\n",
    "    job_details = wait_for_job_completion(job_arn, region)\n",
    "    print(f\"Job completed with status: {job_details['status']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Download and Analyze Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://gili-datasets-us-east-1/evaluation/results//meetingbank-nova-micro-20250531184651/\n",
      "prefix=evaluation/results/meetingbank-nova-micro-20250531184651/\n",
      "Downloading evaluation/results/meetingbank-nova-micro-20250531184651/b63z3uekqo2i/models/amazon.nova-micro-v1:0/taskTypes/General/datasets/meetingbank_dataset/70402edd-5f97-4233-8b25-24dd1f230d22_output.jsonl to ./results/meetingbank-nova-micro-20250531184651/output.jsonl\n",
      "Results downloaded to: ./results/meetingbank-nova-micro-20250531184651\n",
      "s3://gili-datasets-us-east-1/evaluation/results//meetingbank-nova-lite-20250531184652/\n",
      "prefix=evaluation/results/meetingbank-nova-lite-20250531184652/\n",
      "Downloading evaluation/results/meetingbank-nova-lite-20250531184652/xzzfgfmzni9k/models/amazon.nova-lite-v1:0/taskTypes/General/datasets/meetingbank_dataset/acb7b4d5-e825-495f-b84f-0037fb405e84_output.jsonl to ./results/meetingbank-nova-lite-20250531184652/output.jsonl\n",
      "Results downloaded to: ./results/meetingbank-nova-lite-20250531184652\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for model in models:\n",
    "    job_name = model['job_name']\n",
    "    results_local_path = f'./results/{job_name}'\n",
    "    # Download the evaluation results\n",
    "    results_base_dir_s3 = f\"{output_s3_uri}/{job_name}/\"\n",
    "    print(results_base_dir_s3)\n",
    "\n",
    "    try:\n",
    "        download_evaluation_results(results_base_dir_s3, results_local_path, region)\n",
    "        print(f\"Results downloaded to: {results_local_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading results: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 2 column 1 (char 11731)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m results_local_path = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m./results/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/output.jsonl\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(results_local_path, \u001b[33m'\u001b[39m\u001b[33mr\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     results = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Extract and display model scores\u001b[39;00m\n\u001b[32m      9\u001b[39m model_scores = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload\u001b[39m(fp, *, \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28;01mNone\u001b[39;00m, object_hook=\u001b[38;5;28;01mNone\u001b[39;00m, parse_float=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    275\u001b[39m         parse_int=\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant=\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook=\u001b[38;5;28;01mNone\u001b[39;00m, **kw):\n\u001b[32m    276\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobject_hook\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_float\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_float\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_int\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_int\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparse_constant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobject_pairs_hook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/decoder.py:348\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    346\u001b[39m end = _w(s, end).end()\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[32m--> \u001b[39m\u001b[32m348\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExtra data\u001b[39m\u001b[33m\"\u001b[39m, s, end)\n\u001b[32m    349\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Extra data: line 2 column 1 (char 11731)"
     ]
    }
   ],
   "source": [
    "# Load and analyze the results\n",
    "for model in models:\n",
    "    job_name = model['job_name']\n",
    "    results_local_path = f'./results/{job_name}/output.jsonl'\n",
    "    with open(results_local_path, 'r') as f:\n",
    "        results = json.load(f)\n",
    "\n",
    "    # Extract and display model scores\n",
    "    model_scores = {}\n",
    "    for model_id in model_ids:\n",
    "        model_name = \"Nova.lite\" if \"haiku\" in model_id else \"Nova.pro\"\n",
    "        model_scores[model_name] = {\n",
    "            \"Relevance\": 0,\n",
    "            \"Accuracy\": 0,\n",
    "            \"Coherence\": 0,\n",
    "            \"Conciseness\": 0\n",
    "        }\n",
    "        \n",
    "        # Extract scores from results (structure depends on actual output format)\n",
    "        # This is a placeholder - adjust based on actual result structure\n",
    "        # model_scores[model_name][\"Relevance\"] = results[model_id][\"metrics\"][\"Relevance\"]\n",
    "        # ...\n",
    "\n",
    "    # Display the scores\n",
    "    scores_df = pd.DataFrame(model_scores)\n",
    "    print(scores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the results\n",
    "ax = scores_df.plot(kind='bar', figsize=(10, 6))\n",
    "ax.set_title('Model Evaluation Scores on MeetingBank Dataset')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_ylim(0, 5)  # Assuming scores are on a 0-5 scale\n",
    "plt.legend(title='Models')\n",
    "plt.tight_layout()\n",
    "plt.savefig('evaluation_results.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusion\n",
    "\n",
    "This notebook demonstrated how to:\n",
    "1. Load the MeetingBank dataset\n",
    "2. Prepare the dataset for Bedrock evaluation\n",
    "3. Create and run a Bedrock evaluation job\n",
    "4. Analyze and visualize the evaluation results\n",
    "\n",
    "The evaluation compared Nova.lite and Nova.pro models on meeting summarization tasks using built-in Bedrock evaluators for Relevance, Accuracy, Coherence, and Conciseness."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
